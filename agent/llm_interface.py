# Code to interface with the local Ollama LLM
def query_llm(prompt):
    return f"LLM Response to: {prompt}"
